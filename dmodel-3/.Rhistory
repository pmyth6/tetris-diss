}
theta = seq(-4, 4, length.out = 1000)
plot.theta = matrix(NA, 1000, 1)
for (i in 1:1000){
plot.theta[i] = post(theta[i])
}
plot(theta, plot.theta, type="l", main="posterior dist")
plot(theta, theta*plot.theta, type="l", main="integrand")
plot(theta, abs(theta*plot.theta), type="l", main="abs(integrand)")
points(theta, 1.45*dnorm(theta,-0.81, sqrt(0.25)), type="l", col="red")
#Importance sampling
N = 1000000
Theta = rnorm(N, -0.81, sqrt(1/4))
posterior.vals = matrix(NA, N, 1)
for (i in 1:N){
posterior.vals[i] = post(Theta[i])
}
g = dnorm(Theta, -0.81, sqrt(1/4))
w = posterior.vals/g
h = Theta
I.hat = sum(w*h)/sum(w)
hist(w, breaks = 40)
plot(theta, plot.theta, type="l", main="posterior dist")
points(rep(I.hat, 100), seq(0,1.7, length.out=100), type="l")
?min
min(1,2)
min(2,1)
alpha = function(x, y){
return(min(1, exp(-0.5*(y^2-x^2))))
}
x = 1
y = rnorm(1, x, 2)
a = alpha(x, y)
u = runif(1, 0, 1)
if (u<a){
x = y
} else {
x = x
}
Xt = MH(500, 1, 0.1)
alpha = function(x, y){
return(min(1, exp(-0.5*(y^2-x^2))))
}
MH = function(n, x0, var){
Xt = matrix(NA, n, 1)
x = x0
Xt[1] = x
for (i in 2:n){
y = rnorm(1, x, sqrt(var))
a = alpha(x, y)
u = runif(1, 0, 1)
if (u<a){
x = y
} else {
x = x
}
Xt[i] = x
}
return(Xt)
}
Xt = MH(500, 1, 0.1)
?ts.plot
ts.plot(Xt)
func = function(theta, phi){
return(10*log(phi) - (1+5*phi)*theta^2 + 40*theta*phi - 81*phi)
}
alpha = function(theta, theta_y, phi, phi_y){
a = func(theta, phi)
b = func(theta_y, phi_y)
return(min(1, b/a))
}
MH = function(theta, phi, tvar, phvar, n){
THETA = 0
PHI = 0
a_T = 0
a_PH = 0
count = 0
THETA[1] = theta
PHI[1] = phi
for (i in 2:n){
count = count+1
theta_y = rnorm(1, theta, sqrt(tvar))
phi_y = rnorm(1, phi, sqrt(phvar))
if (phi_y >0){
u = runif(1, 0, 1)
logalpha = alpha(theta, theta_y, phi, phi_y)
if (log(u) < logalpha){
theta = theta_y
phi = phi_y
a_T = a_T +1
a_PH = a_PH +1
}
}
THETA[i] = theta
PHI[i] = phi
}
return(list(T = THETA, PH = PHI, aT = a_T/count, aPH = a_PH/count))
}
S = MH(1, 2, 0.25, 1, 10000)
par(mfrow=c(3,2))
par(mar = c(2, 2, 2, 2))
ts.plot(S$T)
ts.plot(S$PH)
hist(S$T)
hist(S$PH)
acf(S$T)
acf(S$PH)
data = read.csv("~/Documents/Uni/Year 4/Dissertation/tetris-diss/tetris-diss/no-UI/log.csv")
#Calculate the average score over every (39,500-40,000) moves
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[i*ind-500:i*ind])
}
#Calculate the average score over every (39,500-40,000) moves
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[i*ind-500:i*ind])
}
max(av.score)
min(av.score)
data$score[1]
data$score[2]
data$score[3]
mean(data$score[1:3])
min(data$score[1*ind-500:1*ind])
max(data$score[1*ind-500:1*ind])
mean(data$score[1*ind-500:1*ind])
var(data$score[1*ind-500:1*ind])
#Calculate the average score over every (39,500-40,000) moves
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
var.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[i*ind-500:i*ind])
var.score[i] = var(data$score[i*ind-500:i*ind])
}
max(var.score)
min(var.score)
data$score[1*ind-500:1*ind] == data$score[2*ind-500:2*ind]
which((data$score[1*ind-500:1*ind] == data$score[2*ind-500:2*ind])==FALSE)
which((data$score[1*ind-500:1*ind] == data$score[66*ind-500:66*ind])==FALSE)
which((data$score[1*ind-500:1*ind] == data$score[76*ind-500:76*ind])==FALSE)
mean(data$score[1*ind-500:1*ind])
which(data$score[1*ind-500:1*ind] != 0)
#Calculate the average score over every (39,500-40,000) moves
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
var.score = 0
max.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[i*ind-500:i*ind]) #mean
var.score[i] = var(data$score[i*ind-500:i*ind]) #variance
max.score[i] = max(data$score[i*ind-500:i*ind]) #variance
}
min(max.score)
data$row.placement[3:5]
setwd("~/Documents/Uni/Year 4/Statistical Machine Learning/Spring/chemicals")
training.data <- read.csv("training_set.csv", header=TRUE)
test.data <- read.csv("test_set.csv", header=TRUE)
readingswhole=matrix(92,5)
readingdata=matrix(NA,2,5)
traininground=round(training.data[3:7])
for(i in 1:5){
readingdata[1,]=apply(traininground,2,median)
readingdata[2,i]=sqrt(var(training.data[i+2]))
} #record means and standard deviations for each reading
readingsadjust=matrix(0,5,92)
for(i in 1:92){
readingsadjust[1,i]=training.data$I[i]
readingsadjust[2,i]=training.data$II[i]/(training.data$Impurity.Percent[i])
readingsadjust[3,i]=training.data$III[i]/(training.data$Impurity.Percent[i])
readingsadjust[4,i]=training.data$IV[i]/(training.data$Impurity.Percent[i])
readingsadjust[5,i]=training.data$V[i]/(training.data$Impurity.Percent[i])
}
width=nrow(training.data)
categorytrain=c(1:width)
#setting up receiver matrix
t=4
for(i in 1:width){
categorytrain[i]="LF" #use L and F by default
if(training.data$I[i]>readingdata[1,1]+readingdata[2,1]){
categorytrain[i]="A"
}
if((training.data$II[i]>readingdata[1,2]+(readingdata[2,2])/2)){
categorytrain[i]="G"
}
if(training.data$III[i]>readingdata[1,3]+readingdata[2,3]){
categorytrain[i]="E"
}
if(training.data$IV[i]>readingdata[1,4]+readingdata[2,4]){
categorytrain[i]="BH" #difference between B and H difficult
}
if(training.data$V[i]>readingdata[1,5]+(readingdata[2,5])/2){
categorytrain[i]="CN" #difference between C and N difficult
}
if(training.data$IV[i]>readingdata[1,4]){
if(training.data$V[i]>readingdata[1,5]+(readingdata[2,5])/2){
categorytrain[i]="K" #K classifier
}
}
if((training.data$II[i]>readingdata[1,2]+(readingdata[2,2])/2)){
if(training.data$V[i]>readingdata[1,5]+(readingdata[2,5])/2){
categorytrain[i]="DJM" #difference between D, J and M difficult
}
}
}
#categorytrain
categoryfound=matrix(0,1,width)
for(i in 1:width){
if(training.data$II[i]>16.7){
categoryfound[i]="DGJM"
}
if(training.data$IV[i]>18){
categoryfound[i]="BH"
}
if(training.data$I[i]>103){
categoryfound[i]="A"
}
if(training.data$III[i]>20){
categoryfound[i]="E"
}
}
#letters left=CFHKL
let1=c("D","G", "J", "M")
let2=c("B", "H")
let3=c("C", "F", "H", "K", "L")#sort unsure letters into groups
for(i in 1:width){
if(categoryfound[i]=="DGJM"){
categoryfound[i]=let1[round(runif(1,0.5,4.5))]#randomly generate within groups
} else if(categoryfound[i]=="BH"){
categoryfound[i]=let2[round(runif(1,0.5,2.5))]
} else if(categoryfound[i]==0){
categoryfound[i]=let3[round(runif(1,0.5,5.5))]
}
}
#repeat for test data
width=100
categorytest=matrix(0,1,width)
for(i in 1:width){
if(test.data$II[i]>16.7){
categorytest[i]="DGJM"
}
if(test.data$IV[i]>18){
categorytest[i]="BH"
}
if(test.data$I[i]>103){
categorytest[i]="A"
}
if(test.data$III[i]>20){
categorytest[i]="E"
}
}
#letters left=CFHKL
let1=c("D","G", "J", "M")
let2=c("B", "H")
let3=c("C", "F", "H", "K", "L")#sort unsure letters into groups
for(i in 1:width){
if(categorytest[i]=="DGJM"){
categorytest[i]=let1[round(runif(1,0.5,4.5))]#randomly generate within groups
} else if(categorytest[i]=="BH"){
categorytest[i]=let2[round(runif(1,0.5,2.5))]
} else if(categorytest[i]==0){
categorytest[i]=let3[round(runif(1,0.5,5.5))]
}
}
print(categorytest)
?sample
training.data <- read.csv("training_set.csv", header=TRUE)
test.data <- read.csv("test_set.csv", header=TRUE)
width=nrow(test.data)
categoryfound=matrix(0,1,width)
for(i in 1:width){
if(training.data$I[i]>103){
categoryfound[i]="A"
}
if(training.data$III[i]>20){
categoryfound[i]="E"
}
}
training.data <- read.csv("training_set.csv", header=TRUE)
test.data <- read.csv("test_set.csv", header=TRUE)
width=nrow(test.data)
categoryfound=matrix(0,1,width)
for(i in 1:width){
if(test.data$I[i]>103){
categoryfound[i]="A"
}
if(test.data$III[i]>20){
categoryfound[i]="E"
}
}
ind = which(categoryfound == 0)
categoryfound[ind] = sample(c("B", "C", "D", "F", "G", "H", "J", "K", "L", "M",
"N", "X"), n.test, replace = TRUE)
training.data <- read.csv("training_set.csv", header=TRUE)
test.data <- read.csv("test_set.csv", header=TRUE)
width=nrow(test.data)
categoryfound=matrix(0,1,width)
for(i in 1:width){
if(test.data$I[i]>103){
categoryfound[i]="A"
}
if(test.data$III[i]>20){
categoryfound[i]="E"
}
}
ind = which(categoryfound == 0)
n.test <- length(ind)
categoryfound[ind] = sample(c("B", "C", "D", "F", "G", "H", "J", "K", "L", "M",
"N", "X"), n.test, replace = TRUE)
View(categoryfound)
training.data <- read.csv("training_set.csv", header=TRUE)
test.data <- read.csv("test_set.csv", header=TRUE)
head(training.data)
head(test.data)
#PREDICTION FORMAT
n.test <- 100
g.hat <- sample(c("A", "B", "C", "D", "E", "F", "G", "H", "J", "K", "L", "M",
"N", "X"), n.test, replace = TRUE)
g.hat = 0
for (i in 1:100){
g.hat[i] = categoryfound[i]
}
library(rpart)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = train)
library(rpart)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
predictions = predict(fit, test.sec, type = "vector")
library(rpart)
library(rpart.plot)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
predictions = predict(fit, test.sec, type = "vector")
library(rpart)
library(rpart.plot)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
predictions = predict(fit, test.data, type = "vector")
library(rpart)
library(rpart.plot)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
predictions = predict(fit, test.data, type = "vector")
library(rpart)
library(rpart.plot)
fit = rpart(Impurity.Percent~ I+II+III+IV+V+Temp, data = training.data)
rpart.plot(fit, box.palette = "auto")
predictions = predict(fit, test.data, type = "vector")
y.hat <- rnorm(n.test,6,1)
y.hat = 0
for (i in 1:100){
y.hat[i] = predictions[i]
}
write.csv(cbind(g.hat,y.hat), file = "chemical_predictions_group_F_week_1.csv",
row.names=FALSE)
ind2 = which(g.hat == "X")
y.hat[ind2] = 0
ind3 = which(y.hat == 0)
write.csv(cbind(g.hat,y.hat), file = "chemical_predictions_group_F_week_1.csv",
row.names=FALSE)
# PACKAGES
library(reshape2)
library(dplyr)
library(ggplot2)
library(stringr)
# LOAD DATA
movies.train = read.csv("ratings_train.csv", header=TRUE)
setwd("~/Documents/Uni/Year 4/Statistical Machine Learning/Spring/movies")
# PACKAGES
library(reshape2)
library(dplyr)
library(ggplot2)
library(stringr)
# LOAD DATA
movies.train = read.csv("ratings_train.csv", header=TRUE)
movies.test = read.csv("ratings_test.csv", header=TRUE)
movies.info = read.csv("movies.csv", header=TRUE)
# Extract the genre of the movie
# Assign a unique number to each unique genre combination
movies <- movies %>%
mutate(genres = as.integer(factor(genres, levels = unique(genres))))
# PACKAGES
library(reshape2)
library(dplyr)
library(ggplot2)
library(stringr)
# LOAD DATA
movies.train = read.csv("ratings_train.csv", header=TRUE)
movies.test = read.csv("ratings_test.csv", header=TRUE)
movies.info = read.csv("movies.csv", header=TRUE)
# TEXT EXTRACTION
movies.train = arrange(movies.train, movieId)
movies = left_join(movies.train, movies.info)
# Extract the year of the movie
year = str_extract(movies$title, "\\(\\d{4}\\)")  # Extracts (YYYY)
year = str_replace_all(year, "[()]", "")   # Removes parentheses
year = as.integer(year) # Convert to integer
movies$title = year
movies = rename(movies, year = title)
# Extract the genre of the movie
# Assign a unique number to each unique genre combination
movies <- movies %>%
mutate(genres = as.integer(factor(genres, levels = unique(genres))))
# Select a specific user (change user_id as needed)
user_id <- 4
user_data <- movies %>% filter(userId == user_id)
# Plot ratings over time with color-coded genres
ggplot(user_data, aes(x = movieId, y = rating, color = factor(genres))) +
geom_point(size = 3) +  # Adjust point size
labs(
title = paste("Ratings of User", user_id),
x = "Movie Id",
y = "Rating",
color = "Genre"
) +
scale_color_manual(values = rainbow(length(user_data$genres))[length(user_data$genres):1])
# Plot ratings against genre
ggplot(user_data, aes(x = genres, y = rating)) +
geom_point(size = 3) +  # Adjust point size
labs(
title = paste("Ratings of User", user_id),
x = "Genre",
y = "Rating",
color = "Genre"
) +
theme(legend.position = "none")
# PREDICTION FORMAT
# ratings.train = read.csv("ratings_train.csv", header=TRUE)
# ratings.test = read.csv("ratings_test.csv", header=TRUE)
# X <- acast(ratings.train, userId ~ movieId, value.var="rating")
# print(X)
#
# user.ids <- sort(unique(ratings.train$userId))
# movie.ids <- sort(unique(ratings.train$movieId))
#
# num.test <- dim(ratings.test)[1]
# predictions <- matrix(NA, num.test, 1)
# for (i in 1:num.test){
#   if (!any(movie.ids==ratings.test[i,]$movieId)){ # if film does not arise in training set
#     predictions[i] <- 3
#     }
#   else
#     { # if film does arise in training set
#       movie.i.col.ind <- which(movie.ids==ratings.test[i,]$movieId)
#       predictions[i] <- mean(X[,movie.i.col.ind],na.rm=TRUE)
#       }
#   }
# write.csv(predictions, file = "film_rating_predictions_group_F_week_1.csv", row.names=FALSE)
max(movies$genres)
which(movies$year == NA)
which(movies$year == "")
setwd("~/Documents/Uni/Year 4/Dissertation/tetris-diss/tetris-diss/dmodel-3")
data = read.csv("log.csv")
data = read.csv("~/Documents/Uni/Year 4/Dissertation/tetris-diss/tetris-diss/no-UI/log.csv")
#Calculate the average score over every (39,500-40,000) moves
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
var.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[i*ind-500:i*ind]) #mean
var.score[i] = var(data$score[i*ind-500:i*ind]) #variance
}
data$score[1*ind-500:1*ind]
which(data$score[i*ind-500:i*ind] != 0)
obs = length(data[,1])
ind = 40000
iter = floor(obs/ind)
av.score = 0
var.score = 0
for (i in 1:iter){
av.score[i] = mean(data$score[(i*ind-500):(i*ind)]) #mean
var.score[i] = var(data$score[(i*ind-500):(i*ind)]) #variance
}
plot(seq(1,iter,1), av.score, xlab="40,000 interval no.",
ylab="average score", main="average score over 500 moves every 40,000 moves")
av.ratio = 0
gaps = 0
for (i in 1:iter){
v = 0
g = 0
for (j in (i*ind-500):(i*ind)){
if (substr(data$move[j], 1, 1) == "v"){
v = v+1
}
g = g + data$gap.left[j]
}
av.ratio[i] = v/500
gaps[i] = g
}
plot(seq(1,iter,1), av.ratio, xlab="40,000 interval no.",
ylab="v/total ratio", main="ratio of v moves over 500 moves every 40,000 moves")
plot(seq(1,iter,1), gaps, xlab="40,000 interval no.",
ylab="total number of gaps left",
main="number of gaps left over 500 moves every 40,000 moves")
